{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Evolutionary Algorithm\n",
    "Inspired by [Genetic Algorithm Cartpole](https://github.com/mymultiverse/GeneticAlgo_OpenAIGymCartPole). I've been wanting to play with OpenAI Gym for quite sometime and never could fully understand RL Agents. When I read breifly about evolutionary alrgorithms they made much more conceptual sense to me that I really dug right in. \n",
    "\n",
    "This is my interpretation of an Evolutionary Algorithm. I have no education in them other than mimicking the examples I found online and adding my own modifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.stats import rankdata\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os, sys\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(layers=[4,4,2,1]):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layers[1],input_shape=(layers[0],),activation='relu'))\n",
    "    for neurons_in_layer in layers[2:-1]:\n",
    "        model.add(Dense(neurons_in_layer,activation='relu'))\n",
    "    model.add(Dense(layers[-1],activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def experience_env(env,individual):\n",
    "    obs = env.reset()\n",
    "    award = 0\n",
    "    done = False\n",
    "    while done == False:\n",
    "        action = individual.predict_classes(s(obs))\n",
    "        #action = individual.predict_proba(s(obs))\n",
    "        # action: (array([ 0.03162412,  0.15706954,  0.0446083 , -0.28510563]), 1.0, False, {})\n",
    "        obs, reward, done, info = env.step(action[0][0])\n",
    "        award += reward\n",
    "    return award\n",
    "\n",
    "def s(obs,num=4):\n",
    "    return np.reshape(obs, [1, num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.658689189203734"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience_env(env,create_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_first_gen(num_individuals=10,layers=[4,6,5,2,1],output_activation='sigmoid'):\n",
    "    generation = []\n",
    "    for i in range(num_individuals):\n",
    "        model = create_model(layers)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=.1),metrics=['accuracy'])\n",
    "        generation.append(model)\n",
    "    return generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few functions are a side project I tried after creating the evolutionary algorithm. I basically wanted to influence the model to dance or sway as it balanced the pole - so i added an extra bit of reward to the total reward to be gained if the model followed a sin or tan wave corresponding to its velocity or pole angle. \n",
    "\n",
    "The difficulty I found was weighing both the reward to survive in addition to the dancing. Too low and the model would fall into a local optima of always recieving full points on pole angle until it fell ~30 frames out. Too high and the model wouldn't behave any different than the originals. \n",
    "\n",
    "In the first few generations I found that the dancing had more influence than lter on. I'd love to play with it more but I'm off to learn more Q-learning as well. Maybe someday I'll be required to create a multivariate reward function and then I'll get to practice again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_tan(fs=600,f=10):\n",
    "#     x = np.arange(fs)\n",
    "#     sin = np.array([np.sin(2*np.pi*f*(i/fs)) for i in x])\n",
    "#     cos = np.array([np.cos(2*np.pi*f*(i/fs)) for i in x])\n",
    "#     tan = np.array([np.tan(2*np.pi*f*(i/fs)) for i in x])\n",
    "#     tan[tan > 100] = 0\n",
    "#     tan = tan/(tan.max()*50) # best f=4\n",
    "#     saw = np.array([signal.sawtooth(2*np.pi*f*(i/fs)) for i in x])\n",
    "#     saw = saw/27 # best f=10\n",
    "#     #return sin/40\n",
    "#     return tan\n",
    "\n",
    "# def dance_reward(observed_run):\n",
    "#     df = pd.DataFrame(observed_run)\n",
    "#     df.columns = ['Cart Position','Cart Velocity','Pole Angle','Pole Velocity']\n",
    "    \n",
    "#     for f in range(3,7):\n",
    "#     #    sig = create_tan(fs=600,f=4) # tan\n",
    "#         sig = create_tan(fs=600,f=f) # saw\n",
    "\n",
    "#         limit = .01\n",
    "#         sig_mask = np.abs(np.copy(sig))\n",
    "#         sig_mask[sig_mask > limit] = 1\n",
    "#         sig_mask[sig_mask < limit] = 0\n",
    "\n",
    "#     #    sig = sig*sig_mask\n",
    "\n",
    "#         target = 'Cart Velocity'\n",
    "#         shift = df[target].shape[0]\n",
    "#         pole_angle_rewards = np.array([])\n",
    "\n",
    "#         start = 0\n",
    "#         end = shift\n",
    "\n",
    "#         for i in range(shift):\n",
    "#             shifted_reward = np.sum(np.abs(sig[start:end]-df[target].values))\n",
    "#             inv_shifted_reward = np.sum(np.abs((-1*sig[start:end])-df[target].values))\n",
    "#             pole_angle_rewards = np.append(pole_angle_rewards,shifted_reward)\n",
    "#             pole_angle_rewards = np.append(pole_angle_rewards,inv_shifted_reward)\n",
    "#             start += 1\n",
    "#             end += 1\n",
    "\n",
    "#     return pole_angle_rewards.min()\n",
    "\n",
    "# def experience_env(env,individual,dance_scale=100):\n",
    "#     obs = env.reset()\n",
    "#     award = 0\n",
    "#     observed_run = []\n",
    "#     done = False\n",
    "#     while done == False:\n",
    "#         action = individual.predict_classes(s(obs))\n",
    "#         #action = individual.predict_proba(s(obs))\n",
    "#         # action: (array([ 0.03162412,  0.15706954,  0.0446083 , -0.28510563]), 1.0, False, {})\n",
    "#         obs, reward, done, info = env.step(action[0][0])\n",
    "#         observed_run.append(obs)\n",
    "#         award += reward\n",
    "#     #return (dance_scale/dance_reward(observed_run))+award\n",
    "#     return award"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model from below for single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_first_gen()[0]\n",
    "#model.load_weights('1000.cartpole')\n",
    "experience_env(env,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generation_experience_env(env,generation,trys=5):\n",
    "    generation_reward = []\n",
    "\n",
    "    for individual in generation:\n",
    "        individual_trys_reward = []\n",
    "        for i in range(trys):\n",
    "            individual_trys_reward.append(experience_env(env,individual))\n",
    "        generation_reward.append(individual_trys_reward)\n",
    "    return generation,np.array(generation_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should go with the median over the sum, clearly some models get 'lucky' and aren't consistent\n",
    "\n",
    "    ([<keras.models.Sequential at 0x1c14d112b0>,\n",
    "      <keras.models.Sequential at 0x1c14bd85f8>,\n",
    "      <keras.models.Sequential at 0x1c14d01240>,\n",
    "      <keras.models.Sequential at 0x1c1498d470>,\n",
    "      <keras.models.Sequential at 0x1c1534e710>],\n",
    "     array([[  9.,   9.,   9.,  10.,  10.,   9.,   8.,   9.,   8.,  10.],\n",
    "            [ 73.,  53.,  88.,  68.,  82.,  62., 109.,  52., 104.,  88.],\n",
    "            [  8.,   9.,   8.,  10.,  10.,  11.,   9.,   9.,  13.,  10.],\n",
    "            [  9.,  27.,  10.,  21.,  25.,  13.,   8.,  10.,  21.,  10.],\n",
    "            [171.,  23.,  41., 200.,  22.,  14.,  38.,  51.,  75.,  31.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<keras.models.Sequential at 0x10ba96550>,\n",
       "  <keras.models.Sequential at 0x1c1070a320>,\n",
       "  <keras.models.Sequential at 0x1c0dcddd68>,\n",
       "  <keras.models.Sequential at 0x1c12d4f160>,\n",
       "  <keras.models.Sequential at 0x1c10257048>,\n",
       "  <keras.models.Sequential at 0x1c100468d0>,\n",
       "  <keras.models.Sequential at 0x1c0f40f160>,\n",
       "  <keras.models.Sequential at 0x1c0daeea58>,\n",
       "  <keras.models.Sequential at 0x1c0d8f1e10>,\n",
       "  <keras.models.Sequential at 0x1c11c2cf60>],\n",
       " array([[ 20.15106472,  19.5523277 ,  19.56489165,  20.71931307,\n",
       "          22.53922186,  19.1728766 ,  20.13360245,  18.97748606,\n",
       "          21.893091  ,  19.0612335 ],\n",
       "        [ 22.3287656 ,  19.91410488,  19.63848349,  20.18279431,\n",
       "          21.4513794 ,  20.89570993,  22.05606179,  19.26677988,\n",
       "          22.54112543,  19.97197681],\n",
       "        [ 60.62601847, 174.78372983,  67.67988314,  44.33174908,\n",
       "          65.03546833,  44.895755  ,  40.59404468,  62.86942585,\n",
       "          56.04534601,  61.97177379],\n",
       "        [ 18.96641508,  20.53866583,  20.42740505,  20.43614804,\n",
       "          22.04980155,  22.75848189,  19.886126  ,  20.07734331,\n",
       "          20.17181653,  22.82409712],\n",
       "        [ 19.61361955,  22.7540976 ,  20.52399636,  18.96985604,\n",
       "          19.00141553,  20.34536239,  19.85689433,  19.42805363,\n",
       "          19.29930741,  19.9570082 ],\n",
       "        [ 19.0855977 ,  19.17656061,  18.96650625,  19.03081397,\n",
       "          20.63340448,  19.67918886,  19.20896008,  19.08656858,\n",
       "          20.16828916,  19.59004624],\n",
       "        [ 18.96722767,  19.68618362,  20.5819236 ,  19.22411161,\n",
       "          19.05678388,  19.77800048,  19.84404792,  20.59904105,\n",
       "          20.43467549,  19.9650052 ],\n",
       "        [ 19.15892504,  20.74980515,  20.84017326,  19.43239643,\n",
       "          20.36017795,  19.13166666,  19.6010624 ,  20.98054492,\n",
       "          21.91676415,  20.71376025],\n",
       "        [ 19.8205547 ,  20.74996703,  19.57043281,  19.56483089,\n",
       "          19.9775292 ,  20.60050603,  19.84223702,  20.78426186,\n",
       "          18.74480203,  19.24421302],\n",
       "        [ 19.13851971,  19.27749018,  19.51162888,  19.42978503,\n",
       "          18.9044362 ,  19.55026203,  19.55540229,  19.52446126,\n",
       "          19.35488405,  20.57487099]]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = create_first_gen(10)\n",
    "gen,gen_reward = generation_experience_env(env,gen,10)\n",
    "gen,gen_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_watch_model(model,layers):\n",
    "    model.save_weights('model.cartpole')\n",
    "    str_layers = ','.join([str(i) for i in layers])\n",
    "    os.system('/Users/xbno/anaconda3/bin/python single_model.py -m model.cartpole -l {}'.format(str_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best(current_reward,num=2):\n",
    "    # rank based on median then sum\n",
    "    top = ((rankdata(np.median(1000/current_reward,axis=1))+rankdata(np.sum(1000/current_reward,axis=1))).max()/(rankdata(np.median(1000/current_reward,axis=1))+rankdata(np.sum(1000/current_reward,axis=1)))).argsort()[-num::][::-1]\n",
    "    print('best models:',top)\n",
    "    print('median:\\t',np.median(current_reward,axis=1))\n",
    "    print('sum:\\t',np.sum(current_reward,axis=1))\n",
    "    return top\n",
    "\n",
    "def survival_of_the_fittest(current_generation,current_reward,fittest=2):\n",
    "    fittest_idx = best(current_reward)\n",
    "    fittest_individuals = [current_generation[idx] for idx in fittest_idx]\n",
    "    fittest_weights = [[layer.get_weights()[0] for layer in individual.layers] for individual in fittest_individuals]\n",
    "    return fittest_weights,fittest_individuals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_to_dna(fittest_weights):\n",
    "    fittest_flattened_dna = []\n",
    "    fittest_weights_shapes = []\n",
    "    for individual_weights in fittest_weights:\n",
    "        flat = np.array([])\n",
    "        weight_shapes = []\n",
    "        for fit_weights in individual_weights:\n",
    "            weight_shapes.append(fit_weights.shape)\n",
    "            flat = np.append(flat,fit_weights)\n",
    "        fittest_flattened_dna.append(flat)\n",
    "        fittest_weights_shapes.append(weight_shapes)\n",
    "    return list(zip(fittest_flattened_dna,fittest_weights_shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutate(dna,chance=1,min_mutations=10,max_mutations=0,alter=True,max_change=.5):\n",
    "    if max_mutations == 0:\n",
    "        max_mutations = dna.shape[0]\n",
    "    div = max_change*1000\n",
    "    severity = np.random.randint(min_mutations,max_mutations)\n",
    "    if np.random.rand() <= chance:\n",
    "        for each_mutation in range(severity):\n",
    "            base = np.random.randint(0,dna.shape[0])\n",
    "            if alter:\n",
    "                change = np.random.randint(0,div)/1000\n",
    "                if np.random.choice(['add','sub']) == 'add':\n",
    "                    dna[base] = dna[base] + change\n",
    "                else:\n",
    "                    dna[base] = dna[base] - change\n",
    "            else:\n",
    "                dna[base] = 1-(np.random.rand()*2)\n",
    "    return dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_dna(dna,weight_shapes):\n",
    "    strand_start = 0\n",
    "    reshaped_dna = []\n",
    "    for shape in weight_shapes:\n",
    "        ind = shape[0]*shape[1]\n",
    "        reshaped_dna.append(dna[strand_start:strand_start+ind].reshape(shape))\n",
    "        reshaped_dna.append(np.zeros((shape[1])))\n",
    "        strand_start += ind\n",
    "    return reshaped_dna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learned always remember to copy items that you're modifying in a loop because the changes will be inherited later down the line as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_next_generation(fittest_dna_and_shapes,num_individuals=10,layers=[4,6,5,2,1],chance=1,max_mutations=20,min_mutations=10,alter=True,max_change=.5):\n",
    "    next_generation_dna_and_shapes = list(fittest_dna_and_shapes)\n",
    "    \n",
    "    # mutate\n",
    "    for individual in range(num_individuals):\n",
    "        random.shuffle(fittest_dna_and_shapes)\n",
    "        dna,weight_shapes = np.copy(fittest_dna_and_shapes[0][0]),np.copy(fittest_dna_and_shapes[0][1])\n",
    "        #print('dna:',fittest_dna_and_shapes[0])\n",
    "        mutated_dna_and_shapes = (mutate(dna,chance=chance,min_mutations=min_mutations,max_mutations=max_mutations,alter=alter,max_change=max_change),weight_shapes)\n",
    "        #print('mutated:',mutated_dna_and_shapes)\n",
    "        next_generation_dna_and_shapes.append(mutated_dna_and_shapes)\n",
    "    \n",
    "    #print(next_generation_dna_and_shapes)\n",
    "    \n",
    "    # dna -> weights\n",
    "    next_generation_weights = []\n",
    "    for (dna,weight_shapes) in next_generation_dna_and_shapes:\n",
    "        #print('next gen pairs:',(dna,weight_shapes))\n",
    "        next_generation_weights.append(reshape_dna(dna,weight_shapes))\n",
    "        \n",
    "    # weights -> models\n",
    "    next_generation = []\n",
    "    for weights in next_generation_weights:\n",
    "        model = create_model(layers)\n",
    "        model.set_weights(weights)\n",
    "        next_generation.append(model)\n",
    "        \n",
    "    return next_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tried a bunch of 'hyper' param settings and this is what I found:\n",
    "\n",
    "1. num_best is amazing at 2, not good at 3 or 1\n",
    "2. max_change from 0-1 is too much, 0-.5 or 0-.33 is better\n",
    "3. the num_experiences makes a huge difference, consistency is important in choosing next best\n",
    "4. also the best models are determined not only by median first important factor, but then by total points. this is key since there tend to be a lot of models at median 200 with total scores differing a lot\n",
    "\n",
    "I'd like to modify the reward function to include having a non-moving or close to vertical pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best seems to be 4,6,4,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- first gen ------\n",
      "best models: [2 0]\n",
      "median:\t [ 10.   9. 104.   9.   9.   9.   9.  10.  10.   9.]\n",
      "sum:\t [ 55.  45. 677.  46.  44.  43.  44.  48.  47.  46.]\n",
      "----- next gen ------\n",
      "max change: 0.23786000000000002\n",
      "best models: [7 3]\n",
      "median:\t [174.   10.   10.  200.   10.    9.    9.5 200.  119.5  70. ]\n",
      "sum:\t [1569.  177.   97. 1946.  133.  101.   95. 1991. 1207.  791.]\n",
      "----- next gen ------\n",
      "max change: 0.07586000000000001\n",
      "best models: [7 2]\n",
      "median:\t [200.  200.  200.  180.5  10.5 123.  123.  200.  200.  191. ]\n",
      "sum:\t [1998. 1945. 2000. 1719.  253. 1290. 1412. 2000. 1923. 1667.]\n",
      "----- next gen ------\n",
      "max change: 0.03464\n",
      "best models: [9 6]\n",
      "median:\t [200. 200. 200.  18. 200. 200. 200. 200. 200. 200.]\n",
      "sum:\t [2000. 2000. 2000.  488. 2000. 1923. 2000. 1986. 1871. 2000.]\n",
      "----- next gen ------\n",
      "max change: 0.004739999999999999\n",
      "best models: [8 5]\n",
      "median:\t [200.  200.  200.  200.  200.  200.  200.  197.5 200.  200. ]\n",
      "sum:\t [2000. 2000. 2000. 2000. 1950. 2000. 1949. 1887. 2000. 1977.]\n",
      "----- next gen ------\n",
      "max change: 0.0008399999999999999\n",
      "best models: [9 7]\n",
      "median:\t [200. 200. 200. 200. 200. 200. 200. 200. 200. 200.]\n",
      "sum:\t [2000. 2000. 2000. 2000. 2000. 2000. 2000. 2000. 1958. 2000.]\n",
      "----- next gen ------\n",
      "----- the end ------\n",
      "perfect score!!!\n",
      "it took 5 generations of 10 individuals. there were 500 cartpole games played!!\n"
     ]
    }
   ],
   "source": [
    "num_individuals = 10\n",
    "num_best = 2\n",
    "num_new_individuals = num_individuals - num_best\n",
    "num_generations = 10\n",
    "num_experiences = 10\n",
    "max_change = .5\n",
    "change_scale = 2.5\n",
    "layers=[4,6,4,1]\n",
    "\n",
    "print('----- first gen ------')\n",
    "first_generation = create_first_gen(num_individuals=num_individuals,layers=layers)\n",
    "current_generation,current_reward = generation_experience_env(env,first_generation)\n",
    "fittest_weights,fittest_individuals = survival_of_the_fittest(current_generation,current_reward)\n",
    "nb_watch_model(fittest_individuals[0],layers)\n",
    "fittest_dna_and_shapes = weights_to_dna(fittest_weights)\n",
    "\n",
    "try:\n",
    "    for i in range(num_generations):\n",
    "        print('----- next gen ------')\n",
    "        # min and max mutations\n",
    "        dna_length = fittest_dna_and_shapes[0][0].shape[0]\n",
    "        min_mutations = int(dna_length/2)\n",
    "        max_mutations = dna_length \n",
    "        \n",
    "        next_generation = create_next_generation(fittest_dna_and_shapes,num_individuals=num_new_individuals,chance=1,alter=True,min_mutations=min_mutations,max_mutations=max_mutations,max_change=max_change,layers=layers)\n",
    "        #next_generation = fittest_individuals+next_generation\n",
    "        current_generation,current_reward = generation_experience_env(env,next_generation,trys=num_experiences)\n",
    "\n",
    "        # scale learning rate\n",
    "        total_reward = current_reward.shape[0]*current_reward.shape[1]*200\n",
    "        #total_current_reward = current_reward.sum()\n",
    "        max_change = ((total_reward - current_reward.sum()) / total_reward)/change_scale\n",
    "        print('max change:',max_change)\n",
    "\n",
    "        fittest_weights,fittest_individuals = survival_of_the_fittest(current_generation,current_reward)\n",
    "        nb_watch_model(fittest_individuals[0],layers)\n",
    "        fittest_dna_and_shapes = weights_to_dna(fittest_weights)\n",
    "    \n",
    "except ValueError:\n",
    "    print('----- the end ------')\n",
    "    print('perfect score!!!')\n",
    "    print('it took {} generations of {} individuals. there were {} cartpole games played!!'.format(i,num_individuals,(i*num_individuals*num_experiences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "watch best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_watch_model(next_generation[0],layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(next_generation,open(\"good_models.p\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
